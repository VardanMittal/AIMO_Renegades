{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":8009768,"sourceType":"datasetVersion","datasetId":4717827},{"sourceId":8524712,"sourceType":"datasetVersion","datasetId":4766079},{"sourceId":33547,"sourceType":"modelInstanceVersion","modelInstanceId":28079}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nos.environ[\"KERAS_BACKEND\"] = \"torch\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\n\nimport keras\nimport keras_nlp\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T05:58:14.120090Z","iopub.execute_input":"2024-06-14T05:58:14.120774Z","iopub.status.idle":"2024-06-14T05:58:33.985551Z","shell.execute_reply.started":"2024-06-14T05:58:14.120743Z","shell.execute_reply":"2024-06-14T05:58:33.984719Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/math-qsa-dataset/train.csv\n/kaggle/input/math-qsa-dataset/test.csv\n/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\n/kaggle/input/ai-mathematical-olympiad-prize/AIMO Prize - Note on Language and Notation.pdf\n/kaggle/input/ai-mathematical-olympiad-prize/train.csv\n/kaggle/input/ai-mathematical-olympiad-prize/test.csv\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/__init__.py\n/kaggle/input/keras-lib-dataset/keras-3.3.3-py3-none-any.whl\n/kaggle/input/keras-lib-dataset/keras_nlp-0.12.1-py3-none-any.whl\n/kaggle/input/llama-3/transformers/8b-hf/1/model.safetensors.index.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/LICENSE\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/USE_POLICY.md\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer.json\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer_config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/example_text_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/requirements.txt\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/eval_details.md\n/kaggle/input/llama-3/transformers/8b-hf/1/special_tokens_map.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/example_chat_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/setup.py\n/kaggle/input/llama-3/transformers/8b-hf/1/generation_config.json\n","output_type":"stream"},{"name":"stderr","text":"2024-06-14 05:58:22.923090: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-14 05:58:22.923196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-14 05:58:23.068441: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pylatexenc","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:33.987176Z","iopub.execute_input":"2024-06-14T05:58:33.987757Z","iopub.status.idle":"2024-06-14T05:58:49.813737Z","shell.execute_reply.started":"2024-06-14T05:58:33.987731Z","shell.execute_reply":"2024-06-14T05:58:49.812769Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting pylatexenc\n  Downloading pylatexenc-2.10.tar.gz (162 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pylatexenc\n  Building wheel for pylatexenc (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=4420e86087632caf8271ea4cc8167c0540518d5439cd60804db09ced9d516524\n  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\nSuccessfully built pylatexenc\nInstalling collected packages: pylatexenc\nSuccessfully installed pylatexenc-2.10\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/ai-mathematical-olympiad-prize\"\n    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n    sequence_length = 512 # max size of input sequence for training\n    batch_size = 1 # size of the input batch in training\n    epochs = 1 # number of epochs to train\nkeras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:49.815114Z","iopub.execute_input":"2024-06-14T05:58:49.815417Z","iopub.status.idle":"2024-06-14T05:58:49.825698Z","shell.execute_reply.started":"2024-06-14T05:58:49.815372Z","shell.execute_reply":"2024-06-14T05:58:49.824802Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/test.csv\")\ndf = pd.concat([df1, df2], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:49.828479Z","iopub.execute_input":"2024-06-14T05:58:49.829465Z","iopub.status.idle":"2024-06-14T05:58:50.038621Z","shell.execute_reply.started":"2024-06-14T05:58:49.829434Z","shell.execute_reply":"2024-06-14T05:58:50.037748Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def is_integer(text):\n    try:\n        if int(text) >= 0:\n            return True\n        else:\n            return False\n    except ValueError:\n        return False\n    \ndf[\"is_integer\"] = df.answer.map(is_integer)\ndf = df[df.is_integer].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:50.039722Z","iopub.execute_input":"2024-06-14T05:58:50.040021Z","iopub.status.idle":"2024-06-14T05:58:50.070224Z","shell.execute_reply.started":"2024-06-14T05:58:50.039997Z","shell.execute_reply":"2024-06-14T05:58:50.069516Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:50.071231Z","iopub.execute_input":"2024-06-14T05:58:50.071523Z","iopub.status.idle":"2024-06-14T05:58:50.096960Z","shell.execute_reply.started":"2024-06-14T05:58:50.071500Z","shell.execute_reply":"2024-06-14T05:58:50.096043Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \ndtypes: bool(1), object(5)\nmemory usage: 294.7+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n\n# Ensure the necessary NLTK data files are downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\n\nclass Preprocessing:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n\n    def convert_draw_command(self, draw_command):\n        pattern_pentagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--cycle.*?\\);')\n        match_pentagon = pattern_pentagon.match(draw_command)\n        if match_pentagon:\n            coords = match_pentagon.groups()\n            return f\"A regular pentagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        pattern_hexagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\),.*?\\);')\n        match_hexagon = pattern_hexagon.match(draw_command)\n        if match_hexagon:\n            coords = match_hexagon.groups()\n            return f\"A regular hexagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        return \"\"\n\n    def convert_dot_label_commands(self, text):\n        pattern_dot = re.compile(r'dot\\(\\((.*?)\\)\\);')\n        text = pattern_dot.sub(r'A point at \\1.', text)\n        \n        pattern_label = re.compile(r'label\\(\"(.*?)\",\\((.*?)\\),.*?\\);')\n        text = pattern_label.sub(r'The point \\1 is at coordinates \\2.', text)\n        \n        return text\n\n    def preprocess_text(self, text):\n        # Remove the [asy] tags\n        text = re.sub(r'\\[asy\\]', '', text)\n        text = re.sub(r'\\[\\/asy\\]', '', text)\n\n        # Split the text into commands\n        commands = text.split('\\n')\n\n        readable_text = []\n        for command in commands:\n            if 'draw' in command:\n                readable_text.append(self.convert_draw_command(command))\n            else:\n                readable_text.append(self.convert_dot_label_commands(command))\n\n        readable_text = ' '.join(readable_text)\n\n        # Tokenize into sentences\n        sentences = sent_tokenize(readable_text)\n\n        # Remove stop words and tokenize the remaining words\n        filtered_sentences = []\n        for sentence in sentences:\n            word_tokens = word_tokenize(sentence)\n            filtered_sentence = [word for word in word_tokens if word.lower() not in self.stop_words]\n            filtered_sentences.append(' '.join(filtered_sentence))\n\n        filtered_text = ' '.join(filtered_sentences)\n        return filtered_text\n\n    def process_dataframe(self, df, text_column):\n        df[f'{text_column}'] = df[text_column].apply(self.preprocess_text)\n        return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:50.098003Z","iopub.execute_input":"2024-06-14T05:58:50.098252Z","iopub.status.idle":"2024-06-14T05:58:51.113427Z","shell.execute_reply.started":"2024-06-14T05:58:50.098230Z","shell.execute_reply":"2024-06-14T05:58:51.112446Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# pipeline = Preprocessing()\n# df = pipeline.process_dataframe(df, \"problem\")","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:51.114578Z","iopub.execute_input":"2024-06-14T05:58:51.114860Z","iopub.status.idle":"2024-06-14T05:58:51.118583Z","shell.execute_reply.started":"2024-06-14T05:58:51.114835Z","shell.execute_reply":"2024-06-14T05:58:51.117678Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:51.119839Z","iopub.execute_input":"2024-06-14T05:58:51.120184Z","iopub.status.idle":"2024-06-14T05:58:51.142254Z","shell.execute_reply.started":"2024-06-14T05:58:51.120152Z","shell.execute_reply":"2024-06-14T05:58:51.141330Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                problem    level  \\\n0     The United States Postal Service charges an ex...  Level 3   \n1     How many integers between 1000 and 2000 have a...  Level 4   \n2     Given that $n$ is an integer and $0 < 4n <30$,...  Level 2   \n3     How many integers between $100$ and $150$ have...  Level 4   \n4     Regular pentagon $ABCDE$ and regular hexagon $...  Level 4   \n...                                                 ...      ...   \n7351  Find the number of real roots of\\n\\[2x^{2001} ...  Level 4   \n7352  For a complex number $z,$ compute the minimum ...  Level 4   \n7353  Compute the smallest positive integer $x$ grea...  Level 4   \n7354  For positive real numbers $a,$ $b,$ $c,$ and $...  Level 5   \n7355  Let $a,$ $b,$ and $c$ be positive real numbers...  Level 5   \n\n                      type                                           solution  \\\n0               Prealgebra  We calculate the desired ratio for each envelo...   \n1               Prealgebra  A number with 15, 20 and 25 as factors must be...   \n2               Prealgebra  Dividing by $4$, we have $0<n<7\\frac{1}{2}$. T...   \n3               Prealgebra  We will break up the problem into cases based ...   \n4               Prealgebra  We know that the sum of the degree measures of...   \n...                    ...                                                ...   \n7351  Intermediate Algebra  We can factor the given equation as\\n\\[(2x + 3...   \n7352  Intermediate Algebra  Geometrically, $|z + 5 - 3i|$ is the distance ...   \n7353  Intermediate Algebra  Let $q$ and $r$ be the remainder when $x$ is d...   \n7354  Intermediate Algebra  Let $S$ denote the given sum.  First, we apply...   \n7355  Intermediate Algebra  By AM-GM,\\n\\[(a - b) + b + \\frac{c^3}{(a - b)b...   \n\n     answer  is_integer  \n0         3        True  \n1         3        True  \n2        28        True  \n3        18        True  \n4       132        True  \n...     ...         ...  \n7351      1        True  \n7352     13        True  \n7353   1700        True  \n7354      9        True  \n7355     12        True  \n\n[7356 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem</th>\n      <th>level</th>\n      <th>type</th>\n      <th>solution</th>\n      <th>answer</th>\n      <th>is_integer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The United States Postal Service charges an ex...</td>\n      <td>Level 3</td>\n      <td>Prealgebra</td>\n      <td>We calculate the desired ratio for each envelo...</td>\n      <td>3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How many integers between 1000 and 2000 have a...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>A number with 15, 20 and 25 as factors must be...</td>\n      <td>3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Given that $n$ is an integer and $0 &lt; 4n &lt;30$,...</td>\n      <td>Level 2</td>\n      <td>Prealgebra</td>\n      <td>Dividing by $4$, we have $0&lt;n&lt;7\\frac{1}{2}$. T...</td>\n      <td>28</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many integers between $100$ and $150$ have...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>We will break up the problem into cases based ...</td>\n      <td>18</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Regular pentagon $ABCDE$ and regular hexagon $...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>We know that the sum of the degree measures of...</td>\n      <td>132</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>Find the number of real roots of\\n\\[2x^{2001} ...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>We can factor the given equation as\\n\\[(2x + 3...</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>For a complex number $z,$ compute the minimum ...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>Geometrically, $|z + 5 - 3i|$ is the distance ...</td>\n      <td>13</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>Compute the smallest positive integer $x$ grea...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>Let $q$ and $r$ be the remainder when $x$ is d...</td>\n      <td>1700</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7354</th>\n      <td>For positive real numbers $a,$ $b,$ $c,$ and $...</td>\n      <td>Level 5</td>\n      <td>Intermediate Algebra</td>\n      <td>Let $S$ denote the given sum.  First, we apply...</td>\n      <td>9</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>Let $a,$ $b,$ and $c$ be positive real numbers...</td>\n      <td>Level 5</td>\n      <td>Intermediate Algebra</td>\n      <td>By AM-GM,\\n\\[(a - b) + b + \\frac{c^3}{(a - b)b...</td>\n      <td>12</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>7356 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import sympy as sp\nfrom sympy.parsing.latex import parse_latex\n!pip install antlr4-python3-runtime\ndef latex_to_math(latex_str):\n    \"\"\"\n    Convert a LaTeX string to a SymPy expression.\n\n    Parameters:\n    latex_str (str): The LaTeX string to convert.\n\n    Returns:\n    sympy.Expr: The corresponding SymPy expression.\n    \"\"\"\n    try:\n        # Parse the LaTeX string\n        sympy_expr = parse_latex(latex_str)\n        return sympy_expr\n    except Exception as e:\n        print(f\"Error parsing LaTeX: {e}\")\n        return None\n\n# Example usage\nlatex_str = r\"\\frac{d}{dx} \\left( x^2 + 2x + 1 \\right)\"\nmath_expr = latex_to_math(latex_str)\nprint(math_expr)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:51.144978Z","iopub.execute_input":"2024-06-14T05:58:51.145240Z","iopub.status.idle":"2024-06-14T05:59:04.111464Z","shell.execute_reply.started":"2024-06-14T05:58:51.145218Z","shell.execute_reply":"2024-06-14T05:59:04.110451Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting antlr4-python3-runtime\n  Downloading antlr4_python3_runtime-4.13.1-py3-none-any.whl.metadata (304 bytes)\nDownloading antlr4_python3_runtime-4.13.1-py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: antlr4-python3-runtime\nSuccessfully installed antlr4-python3-runtime-4.13.1\nError parsing LaTeX: LaTeX parsing requires the antlr4 Python package, provided by pip (antlr4-python3-runtime) or conda (antlr-python-runtime), version 4.11\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.113088Z","iopub.execute_input":"2024-06-14T05:59:04.113589Z","iopub.status.idle":"2024-06-14T05:59:04.118968Z","shell.execute_reply.started":"2024-06-14T05:59:04.113548Z","shell.execute_reply":"2024-06-14T05:59:04.117952Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df[\"prompt\"] = df.progress_apply(lambda row: template.format(problem=row.problem,\n                                                             solution=f\"{row.solution}\\n\\nAnswer:\\n{row.answer}\"),\n                                                             axis=1)\ndata = df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.120039Z","iopub.execute_input":"2024-06-14T05:59:04.120297Z","iopub.status.idle":"2024-06-14T05:59:04.473066Z","shell.execute_reply.started":"2024-06-14T05:59:04.120275Z","shell.execute_reply":"2024-06-14T05:59:04.472206Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7356 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02cb16c686c64f6fa1b71850c6ae479e"}},"metadata":{}}]},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Role\", \"Instruction\", \"Problem\", \"Solution\", \"Answer\"],\n                           [\"blue\", \"yellow\", \"red\", \"cyan\", \"green\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.474326Z","iopub.execute_input":"2024-06-14T05:59:04.474623Z","iopub.status.idle":"2024-06-14T05:59:04.479926Z","shell.execute_reply.started":"2024-06-14T05:59:04.474598Z","shell.execute_reply":"2024-06-14T05:59:04.478938Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Take a random sample\nsample = data[12]\n\n# Give colors to Instruction, Response and Category\nsample = colorize_text(sample)\n\n# Show sample in markdown\ndisplay(Markdown(sample))","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.481160Z","iopub.execute_input":"2024-06-14T05:59:04.481568Z","iopub.status.idle":"2024-06-14T05:59:04.492752Z","shell.execute_reply.started":"2024-06-14T05:59:04.481536Z","shell.execute_reply":"2024-06-14T05:59:04.491940Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Role:</font>**\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n\n\n\n**<font color='yellow'>Instruction:</font>**\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n\n\n\n**<font color='red'>Problem:</font>**\nWhat is the largest positive multiple of $12$ that is less than $350?$\n\n\n\n**<font color='cyan'>Solution:</font>**\nDividing $350$ by $12$ gives a quotient $29$ with a remainder of $2$. In other words, \\[350=12\\cdot29+2.\\]Thus, $29\\cdot12=\\boxed{348}$ is the largest multiple of $12$ which is less than $350.$\n\n\n\n**<font color='green'>Answer:</font>**\n348"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.493747Z","iopub.execute_input":"2024-06-14T05:59:04.493982Z","iopub.status.idle":"2024-06-14T05:59:04.512162Z","shell.execute_reply.started":"2024-06-14T05:59:04.493962Z","shell.execute_reply":"2024-06-14T05:59:04.511245Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \n 6   prompt      7356 non-null   object\ndtypes: bool(1), object(6)\nmemory usage: 352.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"Markdown(colorize_text(df[\"prompt\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.513336Z","iopub.execute_input":"2024-06-14T05:59:04.513964Z","iopub.status.idle":"2024-06-14T05:59:04.522792Z","shell.execute_reply.started":"2024-06-14T05:59:04.513932Z","shell.execute_reply":"2024-06-14T05:59:04.521900Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Role:</font>**\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n\n\n\n**<font color='yellow'>Instruction:</font>**\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n\n\n\n**<font color='red'>Problem:</font>**\nThe United States Postal Service charges an extra $\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\$0.11$ in postage be paid? \\begin{tabular}[t]{ccc}\nEnvelope & Length in inches & Height in inches\\\\\\hline\nA &6 &4\\\\\nB &9 &3\\\\\nC &6 &6\\\\\nD &11 &4\n\\end{tabular}\n\n\n\n**<font color='cyan'>Solution:</font>**\nWe calculate the desired ratio for each envelope: \\begin{align*}\n\\text{A} &= \\frac{6}{4} = 1.5 \\\\\n\\text{B} &= \\frac{9}{3} = 3 \\\\\n\\text{C} &= \\frac{6}{6} = 1 \\\\\n\\text{D} &= \\frac{11}{4} = 2.75\n\\end{align*} $\\text B,$ $\\text C,$ and $\\text D$ are out of range, so the answer is $\\boxed{3}.$\n\n\n\n**<font color='green'>Answer:</font>**\n3"},"metadata":{}}]},{"cell_type":"code","source":"df[\"solution\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:59:04.524074Z","iopub.execute_input":"2024-06-14T05:59:04.524447Z","iopub.status.idle":"2024-06-14T05:59:04.533216Z","shell.execute_reply.started":"2024-06-14T05:59:04.524412Z","shell.execute_reply":"2024-06-14T05:59:04.532357Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'We calculate the desired ratio for each envelope: \\\\begin{align*}\\n\\\\text{A} &= \\\\frac{6}{4} = 1.5 \\\\\\\\\\n\\\\text{B} &= \\\\frac{9}{3} = 3 \\\\\\\\\\n\\\\text{C} &= \\\\frac{6}{6} = 1 \\\\\\\\\\n\\\\text{D} &= \\\\frac{11}{4} = 2.75\\n\\\\end{align*} $\\\\text B,$ $\\\\text C,$ and $\\\\text D$ are out of range, so the answer is $\\\\boxed{3}.$'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport transformers\nimport torch\n\nmodel = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model, model_max_length=512)\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:43:15.271489Z","iopub.execute_input":"2024-06-14T06:43:15.272510Z","iopub.status.idle":"2024-06-14T06:44:18.225631Z","shell.execute_reply.started":"2024-06-14T06:43:15.272474Z","shell.execute_reply":"2024-06-14T06:44:18.223717Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23960ad283dc47fda53c6ae59e0c7c97"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def split_text_into_prompt_completion(df, text_column):\n    prompts = []\n    completions = []\n\n    for index, row in df.iterrows():\n        text = row[text_column]\n        \n        # Split based on \"Solution:\"\n        problem_part, solution_part = text.split(\"Solution:\", 1)\n        \n        # Ensure to keep the \"Solution:\" keyword in the completion\n        solution_part = \"Solution:\" + solution_part\n        \n        # Append to lists\n        prompts.append(problem_part.strip())\n        completions.append(solution_part.strip())\n    \n    # Create new DataFrame\n    split_df = pd.DataFrame({\n        \"prompt\": prompts,\n        \"completion\": completions\n    })\n    \n    return split_df\n\n# Example usage\ndata = split_text_into_prompt_completion(df, 'prompt')","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:44:22.067987Z","iopub.execute_input":"2024-06-14T06:44:22.068648Z","iopub.status.idle":"2024-06-14T06:44:22.499641Z","shell.execute_reply.started":"2024-06-14T06:44:22.068615Z","shell.execute_reply":"2024-06-14T06:44:22.498865Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:44:23.441028Z","iopub.execute_input":"2024-06-14T06:44:23.441400Z","iopub.status.idle":"2024-06-14T06:44:23.459241Z","shell.execute_reply.started":"2024-06-14T06:44:23.441362Z","shell.execute_reply":"2024-06-14T06:44:23.458320Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                                 prompt  \\\n0     Role:\\nYou are an advanced AI system with exce...   \n1     Role:\\nYou are an advanced AI system with exce...   \n2     Role:\\nYou are an advanced AI system with exce...   \n3     Role:\\nYou are an advanced AI system with exce...   \n4     Role:\\nYou are an advanced AI system with exce...   \n...                                                 ...   \n7351  Role:\\nYou are an advanced AI system with exce...   \n7352  Role:\\nYou are an advanced AI system with exce...   \n7353  Role:\\nYou are an advanced AI system with exce...   \n7354  Role:\\nYou are an advanced AI system with exce...   \n7355  Role:\\nYou are an advanced AI system with exce...   \n\n                                             completion  \n0     Solution:\\nWe calculate the desired ratio for ...  \n1     Solution:\\nA number with 15, 20 and 25 as fact...  \n2     Solution:\\nDividing by $4$, we have $0<n<7\\fra...  \n3     Solution:\\nWe will break up the problem into c...  \n4     Solution:\\nWe know that the sum of the degree ...  \n...                                                 ...  \n7351  Solution:\\nWe can factor the given equation as...  \n7352  Solution:\\nGeometrically, $|z + 5 - 3i|$ is th...  \n7353  Solution:\\nLet $q$ and $r$ be the remainder wh...  \n7354  Solution:\\nLet $S$ denote the given sum.  Firs...  \n7355  Solution:\\nBy AM-GM,\\n\\[(a - b) + b + \\frac{c^...  \n\n[7356 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe calculate the desired ratio for ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nA number with 15, 20 and 25 as fact...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nDividing by $4$, we have $0&lt;n&lt;7\\fra...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe will break up the problem into c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe know that the sum of the degree ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe can factor the given equation as...</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nGeometrically, $|z + 5 - 3i|$ is th...</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nLet $q$ and $r$ be the remainder wh...</td>\n    </tr>\n    <tr>\n      <th>7354</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nLet $S$ denote the given sum.  Firs...</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nBy AM-GM,\\n\\[(a - b) + b + \\frac{c^...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7356 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data = []\nprompt = data[\"prompt\"]\ncompletion = data[\"completion\"]\ninput_texts = [prompt + tokenizer.eos_token + completion for prompt, completion in zip(data[\"prompt\"], data[\"completion\"])]\n\nfor input_text in input_texts:\n    tokenized_input = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n    tokenized_data.append(tokenized_input)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:44:26.794316Z","iopub.execute_input":"2024-06-14T06:44:26.795021Z","iopub.status.idle":"2024-06-14T06:44:26.944564Z","shell.execute_reply.started":"2024-06-14T06:44:26.794988Z","shell.execute_reply":"2024-06-14T06:44:26.943303Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m input_texts \u001b[38;5;241m=\u001b[39m [prompt \u001b[38;5;241m+\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token \u001b[38;5;241m+\u001b[39m completion \u001b[38;5;28;01mfor\u001b[39;00m prompt, completion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_text \u001b[38;5;129;01min\u001b[39;00m input_texts:\n\u001b[0;32m----> 7\u001b[0m     tokenized_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     tokenized_data\u001b[38;5;241m.\u001b[39mappend(tokenized_input)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2883\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2882\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2883\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2989\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2970\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2971\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2986\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2987\u001b[0m     )\n\u001b[1;32m   2988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2992\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3053\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3053\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[1;32m   3063\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3064\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3081\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2788\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 2788\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2789\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2792\u001b[0m     )\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2796\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2800\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2801\u001b[0m ):\n","\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."],"ename":"ValueError","evalue":"Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.","output_type":"error"}]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Create a list of dictionaries with 'input_ids' and 'attention_mask'\ntrain_data = []\nfor item in tokenized_data:\n    train_data.append({\n        'input_ids': item['input_ids'].squeeze(),\n        'attention_mask': item['attention_mask'].squeeze()\n    })\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_dict(train_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n\nmodel = AutoModelForCausalLM.from_pretrained(model, torch_dtype=torch.float16)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n    logging_steps=200,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\n\n# Train the model\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"path_to_save_your_model\")\ntokenizer.save_pretrained(\"path_to_save_your_model\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load the fine-tuned model and tokenizer\nfine_tuned_model = AutoModelForCausalLM.from_pretrained(\"path_to_save_your_model\")\nfine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"path_to_save_your_model\")\n\n# Create a pipeline\ngeneration_pipeline = pipeline(\n    \"text-generation\",\n    model=fine_tuned_model,\n    tokenizer=fine_tuned_tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\n\n# Generate text\nprompt = \"Your test prompt\"\ngenerated_text = generation_pipeline(prompt)\nprint(generated_text)","metadata":{},"execution_count":null,"outputs":[]}]}