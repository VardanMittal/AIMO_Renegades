{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":8009768,"sourceType":"datasetVersion","datasetId":4717827},{"sourceId":8152502,"sourceType":"datasetVersion","datasetId":4821830},{"sourceId":8524712,"sourceType":"datasetVersion","datasetId":4766079},{"sourceId":27825,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":22009}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nos.environ[\"KERAS_BACKEND\"] = \"torch\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\n\nimport keras\nimport keras_nlp\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T13:32:29.167129Z","iopub.execute_input":"2024-06-10T13:32:29.167543Z","iopub.status.idle":"2024-06-10T13:32:45.393682Z","shell.execute_reply.started":"2024-06-10T13:32:29.167507Z","shell.execute_reply":"2024-06-10T13:32:45.392657Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/model.safetensors.index.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/model-00003-of-00003.safetensors\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/config.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/tokenizer.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/model-00001-of-00003.safetensors\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/tokenizer_config.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/model-00002-of-00003.safetensors\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/special_tokens_map.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/tokenizer.model\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/added_tokens.json\n/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch/generation_config.json\n/kaggle/input/keras-lib-dataset/keras-3.3.3-py3-none-any.whl\n/kaggle/input/keras-lib-dataset/keras_nlp-0.12.1-py3-none-any.whl\n/kaggle/input/gemma/keras/gemma_1.1_instruct_2b_en/3/config.json\n/kaggle/input/gemma/keras/gemma_1.1_instruct_2b_en/3/tokenizer.json\n/kaggle/input/gemma/keras/gemma_1.1_instruct_2b_en/3/metadata.json\n/kaggle/input/gemma/keras/gemma_1.1_instruct_2b_en/3/model.weights.h5\n/kaggle/input/gemma/keras/gemma_1.1_instruct_2b_en/3/assets/tokenizer/vocabulary.spm\n/kaggle/input/math-qsa-dataset/train.csv\n/kaggle/input/math-qsa-dataset/test.csv\n/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\n/kaggle/input/ai-mathematical-olympiad-prize/AIMO Prize - Note on Language and Notation.pdf\n/kaggle/input/ai-mathematical-olympiad-prize/train.csv\n/kaggle/input/ai-mathematical-olympiad-prize/test.csv\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/__init__.py\n","output_type":"stream"},{"name":"stderr","text":"2024-06-10 13:32:37.641379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-10 13:32:37.641554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-10 13:32:37.784657: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pylatexenc","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:32:49.696570Z","iopub.execute_input":"2024-06-10T13:32:49.697621Z","iopub.status.idle":"2024-06-10T13:33:02.880611Z","shell.execute_reply.started":"2024-06-10T13:32:49.697584Z","shell.execute_reply":"2024-06-10T13:33:02.879425Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pylatexenc in /opt/conda/lib/python3.10/site-packages (2.10)\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/ai-mathematical-olympiad-prize\"\n    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n    sequence_length = 512 # max size of input sequence for training\n    batch_size = 1 # size of the input batch in training\n    epochs = 1 # number of epochs to train\nkeras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:14.006867Z","iopub.execute_input":"2024-06-10T13:33:14.007442Z","iopub.status.idle":"2024-06-10T13:33:14.016953Z","shell.execute_reply.started":"2024-06-10T13:33:14.007403Z","shell.execute_reply":"2024-06-10T13:33:14.016012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/test.csv\")\ndf = pd.concat([df1, df2], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:17.309920Z","iopub.execute_input":"2024-06-10T13:33:17.310278Z","iopub.status.idle":"2024-06-10T13:33:17.426072Z","shell.execute_reply.started":"2024-06-10T13:33:17.310248Z","shell.execute_reply":"2024-06-10T13:33:17.425026Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def is_integer(text):\n    try:\n        if int(text) >= 0:\n            return True\n        else:\n            return False\n    except ValueError:\n        return False\n    \ndf[\"is_integer\"] = df.answer.map(is_integer)\ndf = df[df.is_integer].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:20.374261Z","iopub.execute_input":"2024-06-10T13:33:20.374645Z","iopub.status.idle":"2024-06-10T13:33:20.406596Z","shell.execute_reply.started":"2024-06-10T13:33:20.374614Z","shell.execute_reply":"2024-06-10T13:33:20.405396Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:25.958476Z","iopub.execute_input":"2024-06-10T13:33:25.959266Z","iopub.status.idle":"2024-06-10T13:33:25.990048Z","shell.execute_reply.started":"2024-06-10T13:33:25.959210Z","shell.execute_reply":"2024-06-10T13:33:25.989047Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \ndtypes: bool(1), object(5)\nmemory usage: 294.7+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n\n# Ensure the necessary NLTK data files are downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\n\nclass Preprocessing:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n\n    def convert_draw_command(self, draw_command):\n        pattern_pentagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--cycle.*?\\);')\n        match_pentagon = pattern_pentagon.match(draw_command)\n        if match_pentagon:\n            coords = match_pentagon.groups()\n            return f\"A regular pentagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        pattern_hexagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\),.*?\\);')\n        match_hexagon = pattern_hexagon.match(draw_command)\n        if match_hexagon:\n            coords = match_hexagon.groups()\n            return f\"A regular hexagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        return \"\"\n\n    def convert_dot_label_commands(self, text):\n        pattern_dot = re.compile(r'dot\\(\\((.*?)\\)\\);')\n        text = pattern_dot.sub(r'A point at \\1.', text)\n        \n        pattern_label = re.compile(r'label\\(\"(.*?)\",\\((.*?)\\),.*?\\);')\n        text = pattern_label.sub(r'The point \\1 is at coordinates \\2.', text)\n        \n        return text\n\n    def preprocess_text(self, text):\n        # Remove the [asy] tags\n        text = re.sub(r'\\[asy\\]', '', text)\n        text = re.sub(r'\\[\\/asy\\]', '', text)\n\n        # Split the text into commands\n        commands = text.split('\\n')\n\n        readable_text = []\n        for command in commands:\n            if 'draw' in command:\n                readable_text.append(self.convert_draw_command(command))\n            else:\n                readable_text.append(self.convert_dot_label_commands(command))\n\n        readable_text = ' '.join(readable_text)\n\n        # Tokenize into sentences\n        sentences = sent_tokenize(readable_text)\n\n        # Remove stop words and tokenize the remaining words\n        filtered_sentences = []\n        for sentence in sentences:\n            word_tokens = word_tokenize(sentence)\n            filtered_sentence = [word for word in word_tokens if word.lower() not in self.stop_words]\n            filtered_sentences.append(' '.join(filtered_sentence))\n\n        filtered_text = ' '.join(filtered_sentences)\n        return filtered_text\n\n    def process_dataframe(self, df, text_column):\n        df[f'{text_column}'] = df[text_column].apply(self.preprocess_text)\n        return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:32.145937Z","iopub.execute_input":"2024-06-10T13:33:32.146704Z","iopub.status.idle":"2024-06-10T13:33:33.490764Z","shell.execute_reply.started":"2024-06-10T13:33:32.146668Z","shell.execute_reply":"2024-06-10T13:33:33.489810Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"pipeline = Preprocessing()\na = pipeline.process_dataframe(df, \"problem\")\n\na['problem'][4]","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:49.517200Z","iopub.execute_input":"2024-06-10T13:33:49.517927Z","iopub.status.idle":"2024-06-10T13:33:54.181504Z","shell.execute_reply.started":"2024-06-10T13:33:49.517893Z","shell.execute_reply":"2024-06-10T13:33:54.180615Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'regular pentagon vertices 0,2.5 , 0,7.5 , 4,10 , 8,7.5 , 8,2.5 . regular hexagon vertices 8,2.5 , 11.5 , -1 , 9 , -5 , 5 , -4.5 , 4,0 . point 0,2.5 . point 0,7.5. dot ( ( 4,10 ) ) ; point 8,7.5 . point 8,2.5 . point 4,0 . point coordinates 0,2.5 . point H coordinates 0,7.5 . point G coordinates 4,10 . point F coordinates 8,7.5 . point E coordinates 8,2.5 . point coordinates 4,0 . point 11.5 , -1 . point 9 , -5 . point 5 , -4.5 . point coordinates 11.5 , -1 . point C coordinates 9 , -5 . point B coordinates 5 , -4.5 .'"},"metadata":{}}]},{"cell_type":"code","source":"a.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:33:56.743440Z","iopub.execute_input":"2024-06-10T13:33:56.744166Z","iopub.status.idle":"2024-06-10T13:33:56.759108Z","shell.execute_reply.started":"2024-06-10T13:33:56.744133Z","shell.execute_reply":"2024-06-10T13:33:56.758071Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \ndtypes: bool(1), object(5)\nmemory usage: 294.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install antlr4-python3-runtime","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:29:50.784391Z","iopub.execute_input":"2024-06-10T12:29:50.784674Z","iopub.status.idle":"2024-06-10T12:30:03.293321Z","shell.execute_reply.started":"2024-06-10T12:29:50.784651Z","shell.execute_reply":"2024-06-10T12:30:03.292282Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: antlr4-python3-runtime in /opt/conda/lib/python3.10/site-packages (4.13.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sympy as sp\nfrom sympy.parsing.latex import parse_latex\n!pip install antlr4-python3-runtime\ndef latex_to_math(latex_str):\n    \"\"\"\n    Convert a LaTeX string to a SymPy expression.\n\n    Parameters:\n    latex_str (str): The LaTeX string to convert.\n\n    Returns:\n    sympy.Expr: The corresponding SymPy expression.\n    \"\"\"\n    try:\n        # Parse the LaTeX string\n        sympy_expr = parse_latex(latex_str)\n        return sympy_expr\n    except Exception as e:\n        print(f\"Error parsing LaTeX: {e}\")\n        return None\n\n# Example usage\nlatex_str = r\"\\frac{d}{dx} \\left( x^2 + 2x + 1 \\right)\"\nmath_expr = latex_to_math(latex_str)\nprint(math_expr)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:30:03.294778Z","iopub.execute_input":"2024-06-10T12:30:03.295113Z","iopub.status.idle":"2024-06-10T12:30:12.048211Z","shell.execute_reply.started":"2024-06-10T12:30:03.295083Z","shell.execute_reply":"2024-06-10T12:30:12.047028Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: antlr4-python3-runtime in /opt/conda/lib/python3.10/site-packages (4.13.1)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mError parsing LaTeX: LaTeX parsing requires the antlr4 Python package, provided by pip (antlr4-python3-runtime) or conda (antlr-python-runtime), version 4.11\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:31:18.691704Z","iopub.execute_input":"2024-06-10T12:31:18.692477Z","iopub.status.idle":"2024-06-10T12:31:18.697620Z","shell.execute_reply.started":"2024-06-10T12:31:18.692443Z","shell.execute_reply":"2024-06-10T12:31:18.696564Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df[\"prompt\"] = df.progress_apply(lambda row: template.format(problem=row.problem,\n                                                             solution=f\"{row.solution}\\n\\nAnswer:\\n{row.answer}\"),\n                                                             axis=1)\ndata = df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:31:19.520461Z","iopub.execute_input":"2024-06-10T12:31:19.521342Z","iopub.status.idle":"2024-06-10T12:31:19.851408Z","shell.execute_reply.started":"2024-06-10T12:31:19.521311Z","shell.execute_reply":"2024-06-10T12:31:19.850519Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7356 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c6130dd12354cc3924b628c4d5e5b29"}},"metadata":{}}]},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Role\", \"Instruction\", \"Problem\", \"Solution\", \"Answer\"],\n                           [\"blue\", \"yellow\", \"red\", \"cyan\", \"green\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:31:21.116864Z","iopub.execute_input":"2024-06-10T12:31:21.117720Z","iopub.status.idle":"2024-06-10T12:31:21.123752Z","shell.execute_reply.started":"2024-06-10T12:31:21.117676Z","shell.execute_reply":"2024-06-10T12:31:21.122680Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Take a random sample\nsample = data[12]\n\n# Give colors to Instruction, Response and Category\nsample = colorize_text(sample)\n\n# Show sample in markdown\ndisplay(Markdown(sample))","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:31:22.569480Z","iopub.execute_input":"2024-06-10T12:31:22.569865Z","iopub.status.idle":"2024-06-10T12:31:22.576331Z","shell.execute_reply.started":"2024-06-10T12:31:22.569835Z","shell.execute_reply":"2024-06-10T12:31:22.575422Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Role:</font>**\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n\n\n\n**<font color='yellow'>Instruction:</font>**\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n\n\n\n**<font color='red'>Problem:</font>**\nlargest positive multiple $ 12 $ less $ 350 ? $\n\n\n\n**<font color='cyan'>Solution:</font>**\nDividing $350$ by $12$ gives a quotient $29$ with a remainder of $2$. In other words, \\[350=12\\cdot29+2.\\]Thus, $29\\cdot12=\\boxed{348}$ is the largest multiple of $12$ which is less than $350.$\n\n\n\n**<font color='green'>Answer:</font>**\n348"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:29:42.870204Z","iopub.execute_input":"2024-06-10T13:29:42.870562Z","iopub.status.idle":"2024-06-10T13:30:07.409305Z","shell.execute_reply.started":"2024-06-10T13:29:42.870534Z","shell.execute_reply":"2024-06-10T13:30:07.408299Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:21.227587Z","iopub.execute_input":"2024-06-10T13:30:21.228274Z","iopub.status.idle":"2024-06-10T13:30:22.722048Z","shell.execute_reply.started":"2024-06-10T13:30:21.228241Z","shell.execute_reply":"2024-06-10T13:30:22.721170Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses all logs below ERROR level\n\nimport tensorflow as tf\n# Your TensorFlow code goes here\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:07.411211Z","iopub.execute_input":"2024-06-10T13:30:07.411519Z","iopub.status.idle":"2024-06-10T13:30:07.416360Z","shell.execute_reply.started":"2024-06-10T13:30:07.411492Z","shell.execute_reply":"2024-06-10T13:30:07.415495Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_name = \"/kaggle/input/mammoth-7b-mistral/mammoth_7B_mistral_pretrained_model_pytorch\"  \nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:27.154211Z","iopub.execute_input":"2024-06-10T13:30:27.155051Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"432ee20a4b324daa833ddc4361137835"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:35:26.055604Z","iopub.execute_input":"2024-06-10T13:35:26.056473Z","iopub.status.idle":"2024-06-10T13:35:26.472477Z","shell.execute_reply.started":"2024-06-10T13:35:26.056437Z","shell.execute_reply":"2024-06-10T13:35:26.471650Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset.from_dict(a)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:35:46.302278Z","iopub.execute_input":"2024-06-10T13:35:46.302658Z","iopub.status.idle":"2024-06-10T13:35:46.373496Z","shell.execute_reply.started":"2024-06-10T13:35:46.302629Z","shell.execute_reply":"2024-06-10T13:35:46.372393Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"problem\"], padding=\"max_length\", truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:35:54.211972Z","iopub.execute_input":"2024-06-10T13:35:54.212368Z","iopub.status.idle":"2024-06-10T13:35:55.149302Z","shell.execute_reply.started":"2024-06-10T13:35:54.212336Z","shell.execute_reply":"2024-06-10T13:35:55.147882Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5593e7dfe7664d8c86b68df2b14c8262"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(examples):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3543\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3545\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n","Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36mtokenize_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(examples):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m\"\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}]}]}