{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":8009768,"sourceType":"datasetVersion","datasetId":4717827},{"sourceId":8524712,"sourceType":"datasetVersion","datasetId":4766079},{"sourceId":33547,"sourceType":"modelInstanceVersion","modelInstanceId":28079}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nos.environ[\"KERAS_BACKEND\"] = \"torch\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\n\nimport keras\nimport keras_nlp\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T06:47:14.009457Z","iopub.execute_input":"2024-06-14T06:47:14.009825Z","iopub.status.idle":"2024-06-14T06:47:33.136899Z","shell.execute_reply.started":"2024-06-14T06:47:14.009774Z","shell.execute_reply":"2024-06-14T06:47:33.135854Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/keras-lib-dataset/keras-3.3.3-py3-none-any.whl\n/kaggle/input/keras-lib-dataset/keras_nlp-0.12.1-py3-none-any.whl\n/kaggle/input/llama-3/transformers/8b-hf/1/model.safetensors.index.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/LICENSE\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/USE_POLICY.md\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer.json\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer_config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/example_text_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/requirements.txt\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/eval_details.md\n/kaggle/input/llama-3/transformers/8b-hf/1/special_tokens_map.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/example_chat_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/setup.py\n/kaggle/input/llama-3/transformers/8b-hf/1/generation_config.json\n/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\n/kaggle/input/ai-mathematical-olympiad-prize/AIMO Prize - Note on Language and Notation.pdf\n/kaggle/input/ai-mathematical-olympiad-prize/train.csv\n/kaggle/input/ai-mathematical-olympiad-prize/test.csv\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/ai-mathematical-olympiad-prize/aimo/__init__.py\n/kaggle/input/math-qsa-dataset/train.csv\n/kaggle/input/math-qsa-dataset/test.csv\n","output_type":"stream"},{"name":"stderr","text":"2024-06-14 06:47:22.327618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-14 06:47:22.327720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-14 06:47:22.468870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pylatexenc","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:33.138847Z","iopub.execute_input":"2024-06-14T06:47:33.139984Z","iopub.status.idle":"2024-06-14T06:47:48.742305Z","shell.execute_reply.started":"2024-06-14T06:47:33.139944Z","shell.execute_reply":"2024-06-14T06:47:48.741202Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting pylatexenc\n  Downloading pylatexenc-2.10.tar.gz (162 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pylatexenc\n  Building wheel for pylatexenc (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=96889a4bbaa66fb53638543c7383096a4cbb3cc0ce85cebaf4e1f749eaae8840\n  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\nSuccessfully built pylatexenc\nInstalling collected packages: pylatexenc\nSuccessfully installed pylatexenc-2.10\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/ai-mathematical-olympiad-prize\"\n    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n    sequence_length = 512 # max size of input sequence for training\n    batch_size = 1 # size of the input batch in training\n    epochs = 1 # number of epochs to train\nkeras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:48.743715Z","iopub.execute_input":"2024-06-14T06:47:48.744039Z","iopub.status.idle":"2024-06-14T06:47:48.753064Z","shell.execute_reply.started":"2024-06-14T06:47:48.744011Z","shell.execute_reply":"2024-06-14T06:47:48.752305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/test.csv\")\ndf = pd.concat([df1, df2], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:48.755430Z","iopub.execute_input":"2024-06-14T06:47:48.755708Z","iopub.status.idle":"2024-06-14T06:47:48.956341Z","shell.execute_reply.started":"2024-06-14T06:47:48.755684Z","shell.execute_reply":"2024-06-14T06:47:48.955450Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def is_integer(text):\n    try:\n        if int(text) >= 0:\n            return True\n        else:\n            return False\n    except ValueError:\n        return False\n    \ndf[\"is_integer\"] = df.answer.map(is_integer)\ndf = df[df.is_integer].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:48.957633Z","iopub.execute_input":"2024-06-14T06:47:48.958020Z","iopub.status.idle":"2024-06-14T06:47:48.989426Z","shell.execute_reply.started":"2024-06-14T06:47:48.957986Z","shell.execute_reply":"2024-06-14T06:47:48.988594Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:48.990705Z","iopub.execute_input":"2024-06-14T06:47:48.991069Z","iopub.status.idle":"2024-06-14T06:47:49.017533Z","shell.execute_reply.started":"2024-06-14T06:47:48.991037Z","shell.execute_reply":"2024-06-14T06:47:49.016596Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \ndtypes: bool(1), object(5)\nmemory usage: 294.7+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n\n# Ensure the necessary NLTK data files are downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\n\nclass Preprocessing:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n\n    def convert_draw_command(self, draw_command):\n        pattern_pentagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--cycle.*?\\);')\n        match_pentagon = pattern_pentagon.match(draw_command)\n        if match_pentagon:\n            coords = match_pentagon.groups()\n            return f\"A regular pentagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        pattern_hexagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\),.*?\\);')\n        match_hexagon = pattern_hexagon.match(draw_command)\n        if match_hexagon:\n            coords = match_hexagon.groups()\n            return f\"A regular hexagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        return \"\"\n\n    def convert_dot_label_commands(self, text):\n        pattern_dot = re.compile(r'dot\\(\\((.*?)\\)\\);')\n        text = pattern_dot.sub(r'A point at \\1.', text)\n        \n        pattern_label = re.compile(r'label\\(\"(.*?)\",\\((.*?)\\),.*?\\);')\n        text = pattern_label.sub(r'The point \\1 is at coordinates \\2.', text)\n        \n        return text\n\n    def preprocess_text(self, text):\n        # Remove the [asy] tags\n        text = re.sub(r'\\[asy\\]', '', text)\n        text = re.sub(r'\\[\\/asy\\]', '', text)\n\n        # Split the text into commands\n        commands = text.split('\\n')\n\n        readable_text = []\n        for command in commands:\n            if 'draw' in command:\n                readable_text.append(self.convert_draw_command(command))\n            else:\n                readable_text.append(self.convert_dot_label_commands(command))\n\n        readable_text = ' '.join(readable_text)\n\n        # Tokenize into sentences\n        sentences = sent_tokenize(readable_text)\n\n        # Remove stop words and tokenize the remaining words\n        filtered_sentences = []\n        for sentence in sentences:\n            word_tokens = word_tokenize(sentence)\n            filtered_sentence = [word for word in word_tokens if word.lower() not in self.stop_words]\n            filtered_sentences.append(' '.join(filtered_sentence))\n\n        filtered_text = ' '.join(filtered_sentences)\n        return filtered_text\n\n    def process_dataframe(self, df, text_column):\n        df[f'{text_column}'] = df[text_column].apply(self.preprocess_text)\n        return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:49.018645Z","iopub.execute_input":"2024-06-14T06:47:49.018954Z","iopub.status.idle":"2024-06-14T06:47:50.150357Z","shell.execute_reply.started":"2024-06-14T06:47:49.018929Z","shell.execute_reply":"2024-06-14T06:47:50.149435Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# pipeline = Preprocessing()\n# df = pipeline.process_dataframe(df, \"problem\")","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:50.151508Z","iopub.execute_input":"2024-06-14T06:47:50.151779Z","iopub.status.idle":"2024-06-14T06:47:50.156656Z","shell.execute_reply.started":"2024-06-14T06:47:50.151756Z","shell.execute_reply":"2024-06-14T06:47:50.155850Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:50.157760Z","iopub.execute_input":"2024-06-14T06:47:50.158066Z","iopub.status.idle":"2024-06-14T06:47:50.178709Z","shell.execute_reply.started":"2024-06-14T06:47:50.158044Z","shell.execute_reply":"2024-06-14T06:47:50.177858Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                problem    level  \\\n0     The United States Postal Service charges an ex...  Level 3   \n1     How many integers between 1000 and 2000 have a...  Level 4   \n2     Given that $n$ is an integer and $0 < 4n <30$,...  Level 2   \n3     How many integers between $100$ and $150$ have...  Level 4   \n4     Regular pentagon $ABCDE$ and regular hexagon $...  Level 4   \n...                                                 ...      ...   \n7351  Find the number of real roots of\\n\\[2x^{2001} ...  Level 4   \n7352  For a complex number $z,$ compute the minimum ...  Level 4   \n7353  Compute the smallest positive integer $x$ grea...  Level 4   \n7354  For positive real numbers $a,$ $b,$ $c,$ and $...  Level 5   \n7355  Let $a,$ $b,$ and $c$ be positive real numbers...  Level 5   \n\n                      type                                           solution  \\\n0               Prealgebra  We calculate the desired ratio for each envelo...   \n1               Prealgebra  A number with 15, 20 and 25 as factors must be...   \n2               Prealgebra  Dividing by $4$, we have $0<n<7\\frac{1}{2}$. T...   \n3               Prealgebra  We will break up the problem into cases based ...   \n4               Prealgebra  We know that the sum of the degree measures of...   \n...                    ...                                                ...   \n7351  Intermediate Algebra  We can factor the given equation as\\n\\[(2x + 3...   \n7352  Intermediate Algebra  Geometrically, $|z + 5 - 3i|$ is the distance ...   \n7353  Intermediate Algebra  Let $q$ and $r$ be the remainder when $x$ is d...   \n7354  Intermediate Algebra  Let $S$ denote the given sum.  First, we apply...   \n7355  Intermediate Algebra  By AM-GM,\\n\\[(a - b) + b + \\frac{c^3}{(a - b)b...   \n\n     answer  is_integer  \n0         3        True  \n1         3        True  \n2        28        True  \n3        18        True  \n4       132        True  \n...     ...         ...  \n7351      1        True  \n7352     13        True  \n7353   1700        True  \n7354      9        True  \n7355     12        True  \n\n[7356 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem</th>\n      <th>level</th>\n      <th>type</th>\n      <th>solution</th>\n      <th>answer</th>\n      <th>is_integer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The United States Postal Service charges an ex...</td>\n      <td>Level 3</td>\n      <td>Prealgebra</td>\n      <td>We calculate the desired ratio for each envelo...</td>\n      <td>3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How many integers between 1000 and 2000 have a...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>A number with 15, 20 and 25 as factors must be...</td>\n      <td>3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Given that $n$ is an integer and $0 &lt; 4n &lt;30$,...</td>\n      <td>Level 2</td>\n      <td>Prealgebra</td>\n      <td>Dividing by $4$, we have $0&lt;n&lt;7\\frac{1}{2}$. T...</td>\n      <td>28</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many integers between $100$ and $150$ have...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>We will break up the problem into cases based ...</td>\n      <td>18</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Regular pentagon $ABCDE$ and regular hexagon $...</td>\n      <td>Level 4</td>\n      <td>Prealgebra</td>\n      <td>We know that the sum of the degree measures of...</td>\n      <td>132</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>Find the number of real roots of\\n\\[2x^{2001} ...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>We can factor the given equation as\\n\\[(2x + 3...</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>For a complex number $z,$ compute the minimum ...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>Geometrically, $|z + 5 - 3i|$ is the distance ...</td>\n      <td>13</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>Compute the smallest positive integer $x$ grea...</td>\n      <td>Level 4</td>\n      <td>Intermediate Algebra</td>\n      <td>Let $q$ and $r$ be the remainder when $x$ is d...</td>\n      <td>1700</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7354</th>\n      <td>For positive real numbers $a,$ $b,$ $c,$ and $...</td>\n      <td>Level 5</td>\n      <td>Intermediate Algebra</td>\n      <td>Let $S$ denote the given sum.  First, we apply...</td>\n      <td>9</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>Let $a,$ $b,$ and $c$ be positive real numbers...</td>\n      <td>Level 5</td>\n      <td>Intermediate Algebra</td>\n      <td>By AM-GM,\\n\\[(a - b) + b + \\frac{c^3}{(a - b)b...</td>\n      <td>12</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>7356 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import sympy as sp\nfrom sympy.parsing.latex import parse_latex\n!pip install antlr4-python3-runtime\ndef latex_to_math(latex_str):\n    \"\"\"\n    Convert a LaTeX string to a SymPy expression.\n\n    Parameters:\n    latex_str (str): The LaTeX string to convert.\n\n    Returns:\n    sympy.Expr: The corresponding SymPy expression.\n    \"\"\"\n    try:\n        # Parse the LaTeX string\n        sympy_expr = parse_latex(latex_str)\n        return sympy_expr\n    except Exception as e:\n        print(f\"Error parsing LaTeX: {e}\")\n        return None\n\n# Example usage\nlatex_str = r\"\\frac{d}{dx} \\left( x^2 + 2x + 1 \\right)\"\nmath_expr = latex_to_math(latex_str)\nprint(math_expr)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:47:50.182001Z","iopub.execute_input":"2024-06-14T06:47:50.182352Z","iopub.status.idle":"2024-06-14T06:48:03.345117Z","shell.execute_reply.started":"2024-06-14T06:47:50.182328Z","shell.execute_reply":"2024-06-14T06:48:03.343887Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting antlr4-python3-runtime\n  Downloading antlr4_python3_runtime-4.13.1-py3-none-any.whl.metadata (304 bytes)\nDownloading antlr4_python3_runtime-4.13.1-py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: antlr4-python3-runtime\nSuccessfully installed antlr4-python3-runtime-4.13.1\nError parsing LaTeX: LaTeX parsing requires the antlr4 Python package, provided by pip (antlr4-python3-runtime) or conda (antlr-python-runtime), version 4.11\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.346576Z","iopub.execute_input":"2024-06-14T06:48:03.346955Z","iopub.status.idle":"2024-06-14T06:48:03.352225Z","shell.execute_reply.started":"2024-06-14T06:48:03.346923Z","shell.execute_reply":"2024-06-14T06:48:03.351226Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df[\"prompt\"] = df.progress_apply(lambda row: template.format(problem=row.problem,\n                                                             solution=f\"{row.solution}\\n\\nAnswer:\\n{row.answer}\"),\n                                                             axis=1)\ndata = df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.353570Z","iopub.execute_input":"2024-06-14T06:48:03.353943Z","iopub.status.idle":"2024-06-14T06:48:03.700557Z","shell.execute_reply.started":"2024-06-14T06:48:03.353910Z","shell.execute_reply":"2024-06-14T06:48:03.699550Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7356 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99231b1b0b0742ef89dd08b1c393fe1f"}},"metadata":{}}]},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Role\", \"Instruction\", \"Problem\", \"Solution\", \"Answer\"],\n                           [\"blue\", \"yellow\", \"red\", \"cyan\", \"green\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.701998Z","iopub.execute_input":"2024-06-14T06:48:03.702639Z","iopub.status.idle":"2024-06-14T06:48:03.708573Z","shell.execute_reply.started":"2024-06-14T06:48:03.702604Z","shell.execute_reply":"2024-06-14T06:48:03.707684Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.722399Z","iopub.execute_input":"2024-06-14T06:48:03.722713Z","iopub.status.idle":"2024-06-14T06:48:03.741139Z","shell.execute_reply.started":"2024-06-14T06:48:03.722690Z","shell.execute_reply":"2024-06-14T06:48:03.740259Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7356 entries, 0 to 7355\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   problem     7356 non-null   object\n 1   level       7356 non-null   object\n 2   type        7356 non-null   object\n 3   solution    7356 non-null   object\n 4   answer      7356 non-null   object\n 5   is_integer  7356 non-null   bool  \n 6   prompt      7356 non-null   object\ndtypes: bool(1), object(6)\nmemory usage: 352.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"Markdown(colorize_text(df[\"prompt\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.742346Z","iopub.execute_input":"2024-06-14T06:48:03.742702Z","iopub.status.idle":"2024-06-14T06:48:03.753438Z","shell.execute_reply.started":"2024-06-14T06:48:03.742672Z","shell.execute_reply":"2024-06-14T06:48:03.752530Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='blue'>Role:</font>**\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n\n\n\n**<font color='yellow'>Instruction:</font>**\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\n\n\n\n**<font color='red'>Problem:</font>**\nThe United States Postal Service charges an extra $\\$0.11$ in postage if the length of an envelope, in inches, divided by its height, in inches, is less than $1.3$ or greater than $2.5.$ For how many of these four envelopes must the extra $\\$0.11$ in postage be paid? \\begin{tabular}[t]{ccc}\nEnvelope & Length in inches & Height in inches\\\\\\hline\nA &6 &4\\\\\nB &9 &3\\\\\nC &6 &6\\\\\nD &11 &4\n\\end{tabular}\n\n\n\n**<font color='cyan'>Solution:</font>**\nWe calculate the desired ratio for each envelope: \\begin{align*}\n\\text{A} &= \\frac{6}{4} = 1.5 \\\\\n\\text{B} &= \\frac{9}{3} = 3 \\\\\n\\text{C} &= \\frac{6}{6} = 1 \\\\\n\\text{D} &= \\frac{11}{4} = 2.75\n\\end{align*} $\\text B,$ $\\text C,$ and $\\text D$ are out of range, so the answer is $\\boxed{3}.$\n\n\n\n**<font color='green'>Answer:</font>**\n3"},"metadata":{}}]},{"cell_type":"code","source":"df[\"solution\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.754622Z","iopub.execute_input":"2024-06-14T06:48:03.754954Z","iopub.status.idle":"2024-06-14T06:48:03.763614Z","shell.execute_reply.started":"2024-06-14T06:48:03.754929Z","shell.execute_reply":"2024-06-14T06:48:03.762837Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'We calculate the desired ratio for each envelope: \\\\begin{align*}\\n\\\\text{A} &= \\\\frac{6}{4} = 1.5 \\\\\\\\\\n\\\\text{B} &= \\\\frac{9}{3} = 3 \\\\\\\\\\n\\\\text{C} &= \\\\frac{6}{6} = 1 \\\\\\\\\\n\\\\text{D} &= \\\\frac{11}{4} = 2.75\\n\\\\end{align*} $\\\\text B,$ $\\\\text C,$ and $\\\\text D$ are out of range, so the answer is $\\\\boxed{3}.$'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport transformers\nimport torch\n\nmodel = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model, model_max_length=512)\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:48:03.764719Z","iopub.execute_input":"2024-06-14T06:48:03.765058Z","iopub.status.idle":"2024-06-14T06:50:14.507366Z","shell.execute_reply.started":"2024-06-14T06:48:03.765029Z","shell.execute_reply":"2024-06-14T06:50:14.506585Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"772867c4df394501960fa781f6202206"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def split_text_into_prompt_completion(df, text_column):\n    prompts = []\n    completions = []\n\n    for index, row in df.iterrows():\n        text = row[text_column]\n        \n        # Split based on \"Solution:\"\n        problem_part, solution_part = text.split(\"Solution:\", 1)\n        \n        # Ensure to keep the \"Solution:\" keyword in the completion\n        solution_part = \"Solution:\" + solution_part\n        \n        # Append to lists\n        prompts.append(problem_part.strip())\n        completions.append(solution_part.strip())\n    \n    # Create new DataFrame\n    split_df = pd.DataFrame({\n        \"prompt\": prompts,\n        \"completion\": completions\n    })\n    \n    return split_df\n\n# Example usage\ndata = split_text_into_prompt_completion(df, 'prompt')","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:50:14.508703Z","iopub.execute_input":"2024-06-14T06:50:14.509353Z","iopub.status.idle":"2024-06-14T06:50:14.918847Z","shell.execute_reply.started":"2024-06-14T06:50:14.509318Z","shell.execute_reply":"2024-06-14T06:50:14.918071Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:50:14.919900Z","iopub.execute_input":"2024-06-14T06:50:14.920184Z","iopub.status.idle":"2024-06-14T06:50:14.930885Z","shell.execute_reply.started":"2024-06-14T06:50:14.920160Z","shell.execute_reply":"2024-06-14T06:50:14.929962Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                 prompt  \\\n0     Role:\\nYou are an advanced AI system with exce...   \n1     Role:\\nYou are an advanced AI system with exce...   \n2     Role:\\nYou are an advanced AI system with exce...   \n3     Role:\\nYou are an advanced AI system with exce...   \n4     Role:\\nYou are an advanced AI system with exce...   \n...                                                 ...   \n7351  Role:\\nYou are an advanced AI system with exce...   \n7352  Role:\\nYou are an advanced AI system with exce...   \n7353  Role:\\nYou are an advanced AI system with exce...   \n7354  Role:\\nYou are an advanced AI system with exce...   \n7355  Role:\\nYou are an advanced AI system with exce...   \n\n                                             completion  \n0     Solution:\\nWe calculate the desired ratio for ...  \n1     Solution:\\nA number with 15, 20 and 25 as fact...  \n2     Solution:\\nDividing by $4$, we have $0<n<7\\fra...  \n3     Solution:\\nWe will break up the problem into c...  \n4     Solution:\\nWe know that the sum of the degree ...  \n...                                                 ...  \n7351  Solution:\\nWe can factor the given equation as...  \n7352  Solution:\\nGeometrically, $|z + 5 - 3i|$ is th...  \n7353  Solution:\\nLet $q$ and $r$ be the remainder wh...  \n7354  Solution:\\nLet $S$ denote the given sum.  Firs...  \n7355  Solution:\\nBy AM-GM,\\n\\[(a - b) + b + \\frac{c^...  \n\n[7356 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe calculate the desired ratio for ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nA number with 15, 20 and 25 as fact...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nDividing by $4$, we have $0&lt;n&lt;7\\fra...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe will break up the problem into c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe know that the sum of the degree ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nWe can factor the given equation as...</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nGeometrically, $|z + 5 - 3i|$ is th...</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nLet $q$ and $r$ be the remainder wh...</td>\n    </tr>\n    <tr>\n      <th>7354</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nLet $S$ denote the given sum.  Firs...</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>Role:\\nYou are an advanced AI system with exce...</td>\n      <td>Solution:\\nBy AM-GM,\\n\\[(a - b) + b + \\frac{c^...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7356 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data = []\nprompt = data[\"prompt\"]\ncompletion = data[\"completion\"]\ninput_texts = [prompt + tokenizer.eos_token + completion for prompt, completion in zip(data[\"prompt\"], data[\"completion\"])]\n\nfor input_text in input_texts:\n    tokenized_input = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n    tokenized_data.append(tokenized_input)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:53:14.084959Z","iopub.execute_input":"2024-06-14T06:53:14.085346Z","iopub.status.idle":"2024-06-14T06:53:23.450460Z","shell.execute_reply.started":"2024-06-14T06:53:14.085317Z","shell.execute_reply":"2024-06-14T06:53:23.449635Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenized_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:55:51.004392Z","iopub.execute_input":"2024-06-14T06:55:51.004765Z","iopub.status.idle":"2024-06-14T06:55:51.016165Z","shell.execute_reply.started":"2024-06-14T06:55:51.004735Z","shell.execute_reply":"2024-06-14T06:55:51.015190Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  9207,    512,   2675,    527,    459,  11084,  15592,   1887,    449,\n          25363,  37072,  33811,    323,   3575,  99246,  17357,     11,  11951,\n           6319,    311,  11886,  34553,   7033,   5435,    320,  86243,   4320,\n            374,    264,   2536,  62035,   7698,      8,   5439,    304,  99013,\n           3645,    505,    279,  15592,  92102,  15136,  64044,    320,  14660,\n             46,      8,  10937,     13,   4718,   3465,    374,    311,  30357,\n          24564,    323,  11886,  57216,  37072,   5435,     11,  45296,    264,\n           5655,   8830,    315,  37072,  19476,    323,    264,   3831,   5845,\n            311,   3881,  20406,  33811,  15174,    382,  17077,    512,     16,\n             13,  10852,   3725,   1373,    323,  58389,    279,   3575,   5224,\n           3984,    304,    279,    330,  32298,      1,   3857,    627,     17,\n             13,    763,    279,    330,  37942,      1,   3857,     11,   3493,\n            264,   6425,    315,    279,   3575,    449,  11944,  16540,    315,\n            701,  20406,  33811,   1920,     13,  13969,    304,   4059,    430,\n           4320,   2011,    387,    264,   2536,  62035,   7698,   1396,    627,\n             18,     13,   2468,    279,    842,     11,   1893,    264,    330,\n          16533,      1,   3857,   1405,    499,    690,   1614,   1193,    279,\n           1620,  35876,    477,  47976,    292,   4320,     11,   2085,    904,\n           5217,   1495,    477,  19775,    382,  32298,    512,    791,   3723,\n           4273,  55317,   5475,  10405,    459,   5066,  59060,      3,     15,\n             13,    806,      3,    304,  78141,    422,    279,   3160,    315,\n            459,  35498,     11,    304,  15271,     11,  18255,    555,   1202,\n           2673,     11,    304,  15271,     11,    374,   2753,   1109,    400,\n             16,     13,     18,      3,    477,   7191,   1109,    400,     17,\n             13,     20,   2475,   1789,   1268,   1690,    315,   1521,   3116,\n          87706,   2011,    279,   5066,  59060,      3,     15,     13,    806,\n              3,    304,  78141,    387,   7318,     30,   1144,   7413,     90,\n           6323,   1299,  44489,     83,  15731,  38154,    534,  63812,    612,\n          17736,    304,  15271,    612,  22147,    304,  15271,  82451,     71,\n           1074,    198,     32,    612,     21,    612,     19,   3505,    198,\n             33,    612,     24,    612,     18,   3505,    198,     34,    612,\n             21,    612,     21,   3505,    198,     35,    612,    806,    612,\n             19,    198,     59,    408,     90,   6323,   1299,     92, 128001,\n          37942,    512,   1687,  11294,    279,  12974,  11595,    369,   1855,\n          35498,     25,   1144,   7413,     90,   6750,      9,    534,     59,\n           1342,     90,     32,     92,  14923,   1144,  38118,     90,     21,\n          15523,     19,     92,    284,    220,     16,     13,     20,  91255,\n             59,   1342,     90,     33,     92,  14923,   1144,  38118,     90,\n             24,  15523,     18,     92,    284,    220,     18,  91255,     59,\n           1342,     90,     34,     92,  14923,   1144,  38118,     90,     21,\n          15523,     21,     92,    284,    220,     16,  91255,     59,   1342,\n             90,     35,     92,  14923,   1144,  38118,     90,    806,  15523,\n             19,     92,    284,    220,     17,     13,   2075,    198,     59,\n            408,     90,   6750,      9,     92,  59060,   1342,    426,   4884,\n          59060,   1342,    356,   4884,    323,  59060,   1342,    423,      3,\n            527,    704,    315,   2134,     11,    779,    279,   4320,    374,\n          59060,  80175,     90,     18,     92,   2475,    271,  16533,    512,\n             18]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Create a list of dictionaries with 'input_ids' and 'attention_mask'\ntrain_data = []\nfor item in tokenized_data:\n    train_data.append({\n        'input_ids': item['input_ids'].squeeze(),\n        'attention_mask': item['attention_mask'].squeeze()\n    })\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_dict(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:53:35.027743Z","iopub.execute_input":"2024-06-14T06:53:35.028632Z","iopub.status.idle":"2024-06-14T06:53:35.964633Z","shell.execute_reply.started":"2024-06-14T06:53:35.028603Z","shell.execute_reply":"2024-06-14T06:53:35.963301Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m     train_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(),\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      9\u001b[0m     })\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to Hugging Face Dataset\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:952\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    950\u001b[0m features \u001b[38;5;241m=\u001b[39m features \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    951\u001b[0m arrow_typed_mapping \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)):\n\u001b[1;32m    954\u001b[0m         data \u001b[38;5;241m=\u001b[39m cast_array_to_feature(data, features[col]) \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'items'","output_type":"error"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n\nmodel = AutoModelForCausalLM.from_pretrained(model, torch_dtype=torch.float16)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n    logging_steps=200,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\n\n# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:50:16.153561Z","iopub.status.idle":"2024-06-14T06:50:16.153949Z","shell.execute_reply.started":"2024-06-14T06:50:16.153746Z","shell.execute_reply":"2024-06-14T06:50:16.153760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"path_to_save_your_model\")\ntokenizer.save_pretrained(\"path_to_save_your_model\")","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:50:16.155687Z","iopub.status.idle":"2024-06-14T06:50:16.156162Z","shell.execute_reply.started":"2024-06-14T06:50:16.155924Z","shell.execute_reply":"2024-06-14T06:50:16.155943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load the fine-tuned model and tokenizer\nfine_tuned_model = AutoModelForCausalLM.from_pretrained(\"path_to_save_your_model\")\nfine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"path_to_save_your_model\")\n\n# Create a pipeline\ngeneration_pipeline = pipeline(\n    \"text-generation\",\n    model=fine_tuned_model,\n    tokenizer=fine_tuned_tokenizer,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\n\n# Generate text\nprompt = \"Your test prompt\"\ngenerated_text = generation_pipeline(prompt)\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T06:50:16.157416Z","iopub.status.idle":"2024-06-14T06:50:16.157912Z","shell.execute_reply.started":"2024-06-14T06:50:16.157627Z","shell.execute_reply":"2024-06-14T06:50:16.157646Z"},"trusted":true},"execution_count":null,"outputs":[]}]}