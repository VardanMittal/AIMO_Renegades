{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":8009768,"sourceType":"datasetVersion","datasetId":4717827},{"sourceId":8524712,"sourceType":"datasetVersion","datasetId":4766079},{"sourceId":33547,"sourceType":"modelInstanceVersion","modelInstanceId":28079},{"sourceId":53293,"sourceType":"modelInstanceVersion","modelInstanceId":28517}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math, re, os, warnings, random\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-18T06:08:46.296541Z","iopub.execute_input":"2024-06-18T06:08:46.297283Z","iopub.status.idle":"2024-06-18T06:09:11.773243Z","shell.execute_reply.started":"2024-06-18T06:08:46.297249Z","shell.execute_reply":"2024-06-18T06:09:11.772259Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1718690933.228622      12 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"localhost\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0618 06:08:53.236913327      12 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0618 06:08:53.236928817      12 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0618 06:08:53.236932064      12 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0618 06:08:53.236934469      12 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0618 06:08:53.236936872      12 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0618 06:08:53.236939157      12 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0618 06:08:53.236967745      12 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0618 06:08:53.236970568      12 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0618 06:08:53.236972782      12 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0618 06:08:53.236974915      12 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0618 06:08:53.236977222      12 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0618 06:08:53.236979544      12 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0618 06:08:53.236981877      12 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0618 06:08:53.236984061      12 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0618 06:08:53.236986265      12 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0618 06:08:53.236988420      12 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0618 06:08:53.236990767      12 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0618 06:08:53.236992968      12 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0618 06:08:53.236995129      12 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0618 06:08:53.237003556      12 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0618 06:08:53.237005732      12 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0618 06:08:53.237007927      12 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0618 06:08:53.237010179      12 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0618 06:08:53.237012359      12 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0618 06:08:53.237014451      12 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0618 06:08:53.237016612      12 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0618 06:08:53.237018937      12 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0618 06:08:53.237021165      12 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0618 06:08:53.237023610      12 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0618 06:08:53.237026789      12 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0618 06:08:53.237029064      12 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0618 06:08:53.237031296      12 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0618 06:08:53.237033705      12 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0618 06:08:53.237035860      12 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0618 06:08:53.237038019      12 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0618 06:08:53.237040189      12 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0618 06:08:53.237042293      12 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0618 06:08:53.237044659      12 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0618 06:08:53.237046883      12 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0618 06:08:53.237049070      12 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0618 06:08:53.237051203      12 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0618 06:08:53.237053309      12 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0618 06:08:53.237055469      12 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0618 06:08:53.237057660      12 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0618 06:08:53.237059880      12 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0618 06:08:53.237244996      12 ev_epoll1_linux.cc:123]               grpc epoll fd: 59\nD0618 06:08:53.237256984      12 ev_posix.cc:113]                      Using polling engine: epoll1\nD0618 06:08:53.248287259      12 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0618 06:08:53.248298770      12 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0618 06:08:53.248307106      12 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0618 06:08:53.248310696      12 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0618 06:08:53.248314010      12 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0618 06:08:53.248317606      12 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0618 06:08:53.248344682      12 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0618 06:08:53.248360195      12 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0618 06:08:53.248377333      12 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0618 06:08:53.248402357      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0618 06:08:53.248410194      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0618 06:08:53.248413538      12 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0618 06:08:53.248417709      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0618 06:08:53.248421046      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0618 06:08:53.248424300      12 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0618 06:08:53.248427793      12 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0618 06:08:53.248458828      12 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0618 06:08:53.250083836      12 ev_epoll1_linux.cc:359]               grpc epoll fd: 61\nI0618 06:08:53.251207332      12 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0618 06:08:53.261123422     102 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0618 06:08:53.261174163     102 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0618 06:08:53.267203300      12 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-06-18T06:08:53.267187304+00:00\"}\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version 2.16.1\nDevice: \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1718690946.914168      12 service.cc:145] XLA service 0x5aec67498320 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1718690946.914229      12 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1718690946.914234      12 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1718690946.914237      12 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1718690946.914240      12 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1718690946.914243      12 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1718690946.914245      12 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1718690946.914248      12 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1718690946.914250      12 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nNumber of replicas: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install plotly","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:11.774978Z","iopub.execute_input":"2024-06-18T06:09:11.775264Z","iopub.status.idle":"2024-06-18T06:09:27.680297Z","shell.execute_reply.started":"2024-06-18T06:09:11.775235Z","shell.execute_reply":"2024-06-18T06:09:27.679018Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting plotly\n  Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/site-packages (from plotly) (8.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from plotly) (24.0)\nInstalling collected packages: plotly\nSuccessfully installed plotly-5.22.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\" # avoid memory fragmentation on JAX backend.\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom IPython.display import display, Markdown\nimport tqdm as notebook_tqdm\n\nimport keras\nimport keras_nlp\n\nimport numpy as np\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:27.681694Z","iopub.execute_input":"2024-06-18T06:09:27.682043Z","iopub.status.idle":"2024-06-18T06:09:28.492460Z","shell.execute_reply.started":"2024-06-18T06:09:27.681996Z","shell.execute_reply":"2024-06-18T06:09:28.491670Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/math-qsa-dataset/test.csv\")\ndf = pd.concat([df1, df2], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:28.494152Z","iopub.execute_input":"2024-06-18T06:09:28.494420Z","iopub.status.idle":"2024-06-18T06:09:28.693090Z","shell.execute_reply.started":"2024-06-18T06:09:28.494393Z","shell.execute_reply":"2024-06-18T06:09:28.692195Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def is_integer(text):\n    try:\n        if int(text) >= 0:\n            return True\n        else:\n            return False\n    except ValueError:\n        return False\n    \ndf[\"is_integer\"] = df.answer.map(is_integer)\ndf = df[df.is_integer].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:28.694249Z","iopub.execute_input":"2024-06-18T06:09:28.694538Z","iopub.status.idle":"2024-06-18T06:09:28.713389Z","shell.execute_reply.started":"2024-06-18T06:09:28.694510Z","shell.execute_reply":"2024-06-18T06:09:28.712603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:28.714573Z","iopub.execute_input":"2024-06-18T06:09:28.714879Z","iopub.status.idle":"2024-06-18T06:09:33.510179Z","shell.execute_reply.started":"2024-06-18T06:09:28.714848Z","shell.execute_reply":"2024-06-18T06:09:33.508902Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.4)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.5.15)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\nInstalling collected packages: nltk\nSuccessfully installed nltk-3.8.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n\n# Ensure the necessary NLTK data files are downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\n\nclass Preprocessing:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n\n    def convert_draw_command(self, draw_command):\n        pattern_pentagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--cycle.*?\\);')\n        match_pentagon = pattern_pentagon.match(draw_command)\n        if match_pentagon:\n            coords = match_pentagon.groups()\n            return f\"A regular pentagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        pattern_hexagon = re.compile(r'draw\\(\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\)--\\((.*?)\\),.*?\\);')\n        match_hexagon = pattern_hexagon.match(draw_command)\n        if match_hexagon:\n            coords = match_hexagon.groups()\n            return f\"A regular hexagon with vertices at {coords[0]}, {coords[1]}, {coords[2]}, {coords[3]}, and {coords[4]}.\"\n        \n        return \"\"\n\n    def convert_dot_label_commands(self, text):\n        pattern_dot = re.compile(r'dot\\(\\((.*?)\\)\\);')\n        text = pattern_dot.sub(r'A point at \\1.', text)\n        \n        pattern_label = re.compile(r'label\\(\"(.*?)\",\\((.*?)\\),.*?\\);')\n        text = pattern_label.sub(r'The point \\1 is at coordinates \\2.', text)\n        \n        return text\n\n    def preprocess_text(self, text):\n        # Remove the [asy] tags\n        text = re.sub(r'\\[asy\\]', '', text)\n        text = re.sub(r'\\[\\/asy\\]', '', text)\n\n        # Split the text into commands\n        commands = text.split('\\n')\n\n        readable_text = []\n        for command in commands:\n            if 'draw' in command:\n                readable_text.append(self.convert_draw_command(command))\n            else:\n                readable_text.append(self.convert_dot_label_commands(command))\n\n        readable_text = ' '.join(readable_text)\n\n        # Tokenize into sentences\n        sentences = sent_tokenize(readable_text)\n\n        # Remove stop words and tokenize the remaining words\n        filtered_sentences = []\n        for sentence in sentences:\n            word_tokens = word_tokenize(sentence)\n            filtered_sentence = [word for word in word_tokens if word.lower() not in self.stop_words]\n            filtered_sentences.append(' '.join(filtered_sentence))\n\n        filtered_text = ' '.join(filtered_sentences)\n        return filtered_text\n\n    def process_dataframe(self, df, text_column):\n        df[f'{text_column}'] = df[text_column].apply(self.preprocess_text)\n        return df\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:33.511583Z","iopub.execute_input":"2024-06-18T06:09:33.511879Z","iopub.status.idle":"2024-06-18T06:09:35.722174Z","shell.execute_reply.started":"2024-06-18T06:09:33.511848Z","shell.execute_reply":"2024-06-18T06:09:35.721337Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Role:\\nYou are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\\n\\nInstruction:\n1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n3. At the end, create a \"Answer\" section where you will state only the final numerical or algebraic answer, without any additional text or narrative.\\n\\nProblem:\\n{problem}\\n\\nSolution:\\n{solution}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:35.723248Z","iopub.execute_input":"2024-06-18T06:09:35.724101Z","iopub.status.idle":"2024-06-18T06:09:35.728647Z","shell.execute_reply.started":"2024-06-18T06:09:35.724066Z","shell.execute_reply":"2024-06-18T06:09:35.727997Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\ndf[\"prompt\"] = df.apply(lambda row: template.format(problem=row.problem,\n                                                             solution=f\"{row.solution}\\n\\nAnswer:\\n{row.answer}\"),\n                                                             axis=1)\ndata = df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:35.729543Z","iopub.execute_input":"2024-06-18T06:09:35.729779Z","iopub.status.idle":"2024-06-18T06:09:35.942966Z","shell.execute_reply.started":"2024-06-18T06:09:35.729748Z","shell.execute_reply":"2024-06-18T06:09:35.942124Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Role\", \"Instruction\", \"Problem\", \"Solution\", \"Answer\"],\n                           [\"blue\", \"yellow\", \"red\", \"cyan\", \"green\"]):\n        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:35.945234Z","iopub.execute_input":"2024-06-18T06:09:35.945535Z","iopub.status.idle":"2024-06-18T06:09:35.950472Z","shell.execute_reply.started":"2024-06-18T06:09:35.945505Z","shell.execute_reply":"2024-06-18T06:09:35.949685Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"def split_text_into_prompt_completion(df, text_column):\n    prompts = []\n    completions = []\n\n    for index, row in df.iterrows():\n        text = row[text_column]\n        \n        # Split based on \"Solution:\"\n        problem_part, solution_part = text.split(\"Solution:\", 1)\n        \n        # Ensure to keep the \"Solution:\" keyword in the completion\n        solution_part = \"Solution:\" + solution_part\n        \n        # Append to lists\n        prompts.append(problem_part.strip())\n        completions.append(solution_part.strip())\n    \n    # Create new DataFrame\n    split_df = pd.DataFrame({\n        \"prompt\": prompts,\n        \"completion\": completions\n    })\n    \n    return split_df\n\n# Example usage\ndata = split_text_into_prompt_completion(df, 'prompt')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:35.951298Z","iopub.execute_input":"2024-06-18T06:09:35.951518Z","iopub.status.idle":"2024-06-18T06:09:36.303907Z","shell.execute_reply.started":"2024-06-18T06:09:35.951495Z","shell.execute_reply":"2024-06-18T06:09:36.302875Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom keras_nlp.models import Llama3CausalLM, Llama3Tokenizer\n\nprompts = data['prompt'].tolist()\nresults = data['completion'].tolist()\n\n# Load the model and tokenizer\nllama_lm = Llama3CausalLM.from_preset(\"llama3_8b_en\", dtype=\"bfloat16\")\ntokenizer = Llama3Tokenizer.from_preset(\"llama3_8b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:09:36.305001Z","iopub.execute_input":"2024-06-18T06:09:36.305276Z","iopub.status.idle":"2024-06-18T06:12:55.902498Z","shell.execute_reply.started":"2024-06-18T06:09:36.305250Z","shell.execute_reply":"2024-06-18T06:12:55.901484Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/merges.txt' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.json' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/merges.txt' from model 'keras/llama3/keras/llama3_8b_en/3' to your Kaggle notebook...\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_prompts = tokenizer(prompts)\ntokenized_results = tokenizer(results)\n\n\nmax_len = max(max(len(seq) for seq in tokenized_prompts), max(len(seq) for seq in tokenized_results))\nprint(max_len)\n# Function to pad sequences","metadata":{"execution":{"iopub.status.busy":"2024-06-18T07:04:40.568630Z","iopub.execute_input":"2024-06-18T07:04:40.569809Z","iopub.status.idle":"2024-06-18T07:05:21.624492Z","shell.execute_reply.started":"2024-06-18T07:04:40.569766Z","shell.execute_reply":"2024-06-18T07:05:21.623468Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"2412\n","output_type":"stream"}]},{"cell_type":"code","source":"def pad_sequences(sequences, max_len, pad_token_id):\n    padded_sequences = np.full((sequences.shape[0], max_len), pad_token_id, dtype=np.int32)\n    for i, seq in enumerate(sequences):\n        padded_sequences[i, :len(seq)] = seq\n    return padded_sequences","metadata":{"execution":{"iopub.status.busy":"2024-06-18T07:09:15.678784Z","iopub.execute_input":"2024-06-18T07:09:15.679328Z","iopub.status.idle":"2024-06-18T07:09:15.684330Z","shell.execute_reply.started":"2024-06-18T07:09:15.679297Z","shell.execute_reply":"2024-06-18T07:09:15.683426Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Pad the tokenized sequences\npad_token_id = tokenizer.pad_token_id\nprint(pad_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T07:09:16.931052Z","iopub.execute_input":"2024-06-18T07:09:16.931426Z","iopub.status.idle":"2024-06-18T07:09:16.936668Z","shell.execute_reply.started":"2024-06-18T07:09:16.931395Z","shell.execute_reply":"2024-06-18T07:09:16.935587Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_prompts.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-18T07:09:17.728908Z","iopub.execute_input":"2024-06-18T07:09:17.729531Z","iopub.status.idle":"2024-06-18T07:09:17.735500Z","shell.execute_reply.started":"2024-06-18T07:09:17.729498Z","shell.execute_reply":"2024-06-18T07:09:17.734096Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TensorShape([7356, None])"},"metadata":{}}]},{"cell_type":"code","source":"\ninput_ids = pad_sequences(tokenized_prompts, max_len, pad_token_id)\noutput_ids = pad_sequences(tokenized_results, max_len, pad_token_id)\n\n\n# Create a TensorFlow dataset\ndataset = tf.data.Dataset.from_tensor_slices((tokenized_prompts, tokenized_results))\nbatch_size = 8  # Adjust according to your TPU capacity\ndataset = dataset.shuffle(len(prompts)).batch(batch_size)\n\n# Define training configuration\nlearning_rate = 1e-5\noptimizer = tf.keras.optimizers.Adam(learning_rate)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nllama_lm.compile(optimizer=optimizer, loss=loss)\n\n# Train the model\nepochs = 3  # Adjust according to your needs\nllama_lm.fit(dataset, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T07:09:19.953907Z","iopub.execute_input":"2024-06-18T07:09:19.954270Z","iopub.status.idle":"2024-06-18T07:09:40.147475Z","shell.execute_reply.started":"2024-06-18T07:09:19.954243Z","shell.execute_reply":"2024-06-18T07:09:40.145909Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"WARNING:absl:`Llama3CausalLMPreprocessor` generates `y` and `sample_weight` based on your input data, but your data already contains `y` or `sample_weight`. Your `y` and `sample_weight` will be ignored.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Adjust according to your needs\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mllama_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py:181\u001b[0m, in \u001b[0;36mPipelineModel.fit\u001b[0;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     (x, y, sample_weight), validation_data \u001b[38;5;241m=\u001b[39m _train_validation_split(\n\u001b[1;32m    177\u001b[0m         (x, y, sample_weight), validation_split\u001b[38;5;241m=\u001b[39mvalidation_split\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    180\u001b[0m x \u001b[38;5;241m=\u001b[39m _convert_inputs_to_dataset(x, y, sample_weight, batch_size)\n\u001b[0;32m--> 181\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(validation_data, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_filexse5ugtd.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_samples\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m     34\u001b[0m         do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1217\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1215\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m   \u001b[43m_py_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1270\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;28;01melse\u001b[39;00m orelse()\n","File \u001b[0;32m/tmp/__autograph_generated_filexse5ugtd.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_samples.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_filejsb_bc1f.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     is_tf_backend \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(config)\u001b[38;5;241m.\u001b[39mbackend, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     is_in_tf_graph \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexecuting_eagerly, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope))\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras_nlp/src/models/llama3/llama3_causal_lm_preprocessor.py:111\u001b[0m, in \u001b[0;36mLlama3CausalLMPreprocessor.call\u001b[0;34m(self, x, y, sample_weight, sequence_length)\u001b[0m\n\u001b[1;32m    103\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Llama3CausalLMPreprocessor` generates `y` and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_weight` based on your input data, but your data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready contains `y` or `sample_weight`. Your `y` and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_weight` will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m sequence_length \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length\n\u001b[0;32m--> 111\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_inputs_to_list_of_tensor_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    112\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(x)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Pad with one extra token to account for the truncation below.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras_nlp/src/utils/keras_utils.py:100\u001b[0m, in \u001b[0;36mconvert_inputs_to_list_of_tensor_segments\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     97\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Error for all other input.\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported input for `x`. `x` should be a string, a list of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings, or a list of tensors. If passing multiple segments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich should packed together, please convert your inputs to a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist of tensors. Received `x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/models/task.py\", line 98, in preprocess_samples  *\n        return self.preprocessor(x, y=y, sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/layers/preprocessing/preprocessing_layer.py\", line 49, in __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/models/llama3/llama3_causal_lm_preprocessor.py\", line 111, in call\n        x = convert_inputs_to_list_of_tensor_segments(x)[0]\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/utils/keras_utils.py\", line 100, in convert_inputs_to_list_of_tensor_segments\n        raise ValueError(\n\n    ValueError: Exception encountered when calling Llama3CausalLMPreprocessor.call().\n    \n    \u001b[1mUnsupported input for `x`. `x` should be a string, a list of strings, or a list of tensors. If passing multiple segments which should packed together, please convert your inputs to a list of tensors. Received `x=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))`\u001b[0m\n    \n    Arguments received by Llama3CausalLMPreprocessor.call():\n      • x=tf.Tensor(shape=(None, None), dtype=int32)\n      • y=tf.Tensor(shape=(None, None), dtype=int32)\n      • sample_weight=None\n      • sequence_length=None\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/models/task.py\", line 98, in preprocess_samples  *\n        return self.preprocessor(x, y=y, sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/layers/preprocessing/preprocessing_layer.py\", line 49, in __call__  *\n        outputs = super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/models/llama3/llama3_causal_lm_preprocessor.py\", line 111, in call\n        x = convert_inputs_to_list_of_tensor_segments(x)[0]\n    File \"/usr/local/lib/python3.10/site-packages/keras_nlp/src/utils/keras_utils.py\", line 100, in convert_inputs_to_list_of_tensor_segments\n        raise ValueError(\n\n    ValueError: Exception encountered when calling Llama3CausalLMPreprocessor.call().\n    \n    \u001b[1mUnsupported input for `x`. `x` should be a string, a list of strings, or a list of tensors. If passing multiple segments which should packed together, please convert your inputs to a list of tensors. Received `x=tf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=int32), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))`\u001b[0m\n    \n    Arguments received by Llama3CausalLMPreprocessor.call():\n      • x=tf.Tensor(shape=(None, None), dtype=int32)\n      • y=tf.Tensor(shape=(None, None), dtype=int32)\n      • sample_weight=None\n      • sequence_length=None\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}